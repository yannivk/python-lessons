{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2, Day 2: File I/O and Data Processing\n",
    "\n",
    "## Programming Concept: File Input/Output\n",
    "\n",
    "Today we'll learn about **File I/O** (Input/Output) - how to read data from files and write data to files. This is crucial for working with real-world datasets and persisting your program's results.\n",
    "\n",
    "### Key Programming Concepts:\n",
    "- **File handles**: Objects that represent connections to files\n",
    "- **Context managers**: Using `with` statements for safe file handling\n",
    "- **Text vs binary modes**: Different ways to read/write file content\n",
    "- **File paths**: Absolute vs relative paths to locate files\n",
    "- **Exception handling**: Dealing with file errors gracefully\n",
    "\n",
    "### Why File I/O Matters:\n",
    "- **Data persistence**: Save your work and results\n",
    "- **Large datasets**: Process data too big to type manually\n",
    "- **Automation**: Read configuration files, process batches of data\n",
    "- **Integration**: Exchange data with other programs and systems\n",
    "- **Real-world applications**: Almost all software works with files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Basic File Reading\n",
    "\n",
    "Let's start by creating and reading simple text files. We'll work with research data stored in various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data file created: participants.csv\n"
     ]
    }
   ],
   "source": [
    "# First, let's create a sample data file to work with\n",
    "sample_data = \"\"\"Participant_ID,Age,Score,Group\n",
    "P001,25,85,A\n",
    "P002,32,92,B\n",
    "P003,28,78,A\n",
    "P004,29,96,B\n",
    "P005,31,88,A\"\"\"\n",
    "\n",
    "# Write this data to a file\n",
    "with open('participants.csv', 'w') as file:\n",
    "    file.write(sample_data)\n",
    "\n",
    "print(\"Sample data file created: participants.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant_ID,Age,Score,Group\n",
      "P001,25,85,A\n",
      "P002,32,92,B\n",
      "P003,28,78,A\n",
      "P004,29,96,B\n",
      "P005,31,88,A\n"
     ]
    }
   ],
   "source": [
    "# Task 1a: Read the entire file\n",
    "# Open the file and read all its contents\n",
    "# Print the contents to see what we're working with\n",
    "with open('participants.csv') as file:\n",
    "    contents = file.read()\n",
    "    print(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: Participant_ID,Age,Score,Group\n",
      "Line 2: P001,25,85,A\n",
      "Line 3: P002,32,92,B\n",
      "Line 4: P003,28,78,A\n",
      "Line 5: P004,29,96,B\n",
      "Line 6: P005,31,88,A\n"
     ]
    }
   ],
   "source": [
    "# Task 1b: Read file line by line\n",
    "# Read the file one line at a time\n",
    "# Print each line with its line number\n",
    "with open('participants.csv') as file:\n",
    "    for line_number, line in enumerate(file, start=1):\n",
    "        print(f\"Line {line_number}: {line.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1c: Parse CSV data\n",
    "# Read the file and convert it to a list of dictionaries\n",
    "# Each participant should be a dictionary with keys: Participant_ID, Age, Score, Group\n",
    "# Hint: The first line is the header with column names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Writing Files and Data Processing\n",
    "\n",
    "Now let's process our data and write results to new files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2a: Calculate and save statistics\n",
    "# From the participant data, calculate:\n",
    "# - Average age\n",
    "# - Average score\n",
    "# - Average score by group\n",
    "# Write these statistics to a new file called 'statistics.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2b: Filter and save high performers\n",
    "# Create a new CSV file with only participants who scored 85 or higher\n",
    "# Save it as 'high_performers.csv' with the same format as the original\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2c: Append new data\n",
    "# Add three new participants to the original file:\n",
    "# P006,27,91,B\n",
    "# P007,33,79,A  \n",
    "# P008,26,94,B\n",
    "# Use append mode to add them without overwriting existing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Working with Different File Formats\n",
    "\n",
    "Real-world data comes in many formats. Let's work with JSON and handle different file structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create sample JSON data\n",
    "experiment_data = {\n",
    "    \"experiment_id\": \"EXP_001\",\n",
    "    \"date\": \"2025-01-08\",\n",
    "    \"participants\": [\n",
    "        {\"id\": \"P001\", \"condition\": \"control\", \"response_time\": 245, \"accuracy\": 0.92},\n",
    "        {\"id\": \"P002\", \"condition\": \"treatment\", \"response_time\": 198, \"accuracy\": 0.95},\n",
    "        {\"id\": \"P003\", \"condition\": \"control\", \"response_time\": 267, \"accuracy\": 0.88},\n",
    "        {\"id\": \"P004\", \"condition\": \"treatment\", \"response_time\": 223, \"accuracy\": 0.93}\n",
    "    ],\n",
    "    \"settings\": {\n",
    "        \"trials_per_participant\": 50,\n",
    "        \"stimulus_duration\": 200,\n",
    "        \"inter_trial_interval\": 500\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "with open('experiment.json', 'w') as file:\n",
    "    json.dump(experiment_data, file, indent=2)\n",
    "\n",
    "print(\"JSON experiment data created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3a: Load and explore JSON data\n",
    "# Read the JSON file and explore its structure\n",
    "# Print the experiment ID, date, and number of participants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3b: Analyze condition differences\n",
    "# Calculate average response time and accuracy for each condition\n",
    "# Save the results to a new JSON file called 'condition_analysis.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3c: Convert JSON to CSV\n",
    "# Extract the participant data and convert it to CSV format\n",
    "# Save as 'experiment_participants.csv'\n",
    "# Include columns: id, condition, response_time, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Error Handling and File Management\n",
    "\n",
    "Real applications need to handle file errors gracefully and manage file operations safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4a: Safe file reading with error handling\n",
    "# Write a function that safely reads a file and returns its contents\n",
    "# If the file doesn't exist, return None and print a helpful message\n",
    "# Test it with both existing and non-existing files\n",
    "\n",
    "def safe_read_file(filename):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4b: File existence checking\n",
    "# Write a function that checks if a file exists before trying to process it\n",
    "# If it exists, read and return the data; if not, create a default file\n",
    "\n",
    "import os\n",
    "\n",
    "def get_or_create_config(filename, default_config):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test with a config file\n",
    "default_settings = {\"theme\": \"dark\", \"font_size\": 12, \"auto_save\": True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4c: Backup and versioning\n",
    "# Write a function that creates a backup of a file before modifying it\n",
    "# The backup should have a timestamp in the filename\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def backup_and_write(filename, new_content):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test the backup function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Data Pipeline Project\n",
    "\n",
    "Let's build a complete data processing pipeline that reads raw data, processes it, and outputs results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample raw data files to process\n",
    "raw_data_files = {\n",
    "    'day1_results.txt': \"P001:85:23.5\\nP002:92:18.7\\nP003:78:28.1\",\n",
    "    'day2_results.txt': \"P001:88:22.1\\nP002:89:19.3\\nP003:82:26.8\",\n",
    "    'day3_results.txt': \"P001:91:21.0\\nP002:94:17.9\\nP003:85:25.2\"\n",
    "}\n",
    "\n",
    "# Create the raw data files\n",
    "for filename, content in raw_data_files.items():\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "print(\"Raw data files created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5a: Data parsing function\n",
    "# Write a function that reads a raw data file and returns structured data\n",
    "# Format: participant_id:score:time (separated by colons)\n",
    "# Return a list of dictionaries with keys: participant, score, time\n",
    "\n",
    "def parse_raw_data(filename):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test with one file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5b: Combine multiple files\n",
    "# Process all raw data files and combine them into a single dataset\n",
    "# Add a 'day' field to track which file each record came from\n",
    "# Save the combined data as 'combined_results.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5c: Generate summary report\n",
    "# Create a summary report with:\n",
    "# - Participant progress over days (average score improvement)\n",
    "# - Best and worst performing participants\n",
    "# - Day-by-day statistics\n",
    "# Save as both 'summary_report.txt' (human-readable) and 'summary_data.json' (machine-readable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Advanced File Operations\n",
    "\n",
    "For those ready to tackle more complex file handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: Log file parser\n",
    "# Create a function that parses log files with timestamps and extracts specific events\n",
    "# Sample log format: \"2025-01-08 10:30:45 - INFO - Participant P001 completed trial 15\"\n",
    "\n",
    "sample_log = \"\"\"2025-01-08 10:30:45 - INFO - Experiment started\n",
    "2025-01-08 10:31:12 - INFO - Participant P001 completed trial 1\n",
    "2025-01-08 10:31:45 - WARNING - Participant P002 timeout on trial 1\n",
    "2025-01-08 10:32:10 - INFO - Participant P001 completed trial 2\n",
    "2025-01-08 10:32:33 - ERROR - System error during trial recording\n",
    "2025-01-08 10:33:01 - INFO - Participant P002 completed trial 2\"\"\"\n",
    "\n",
    "with open('experiment.log', 'w') as file:\n",
    "    file.write(sample_log)\n",
    "\n",
    "# Write a function to extract all events for a specific participant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2: Configuration file manager\n",
    "# Create a class that manages configuration files with validation\n",
    "# Should support getting/setting values, saving changes, and reverting to defaults\n",
    "\n",
    "class ConfigManager:\n",
    "    def __init__(self, config_file):\n",
    "        # Your code here\n",
    "        pass\n",
    "    \n",
    "    def get(self, key, default=None):\n",
    "        # Your code here\n",
    "        pass\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        # Your code here\n",
    "        pass\n",
    "    \n",
    "    def save(self):\n",
    "        # Your code here\n",
    "        pass\n",
    "\n",
    "# Test the configuration manager\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scRNA-seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
